package com.example;

import org.apache.commons.text.StringTokenizer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.fs.FileSystem;

import java.util.*;
import java.io.*;
import java.net.URI;

public class Main {

    // è¯»å–æ–‡ä»¶å¹¶æ‹†åˆ†å•è¯ï¼Œå°†å•è¯æŒ‰æƒ…æ„Ÿå‚¨å­˜è¯é¢‘
    public static class mapper extends Mapper<Object, Text, Text, IntWritable>{
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();
        private Set<String> stopWords = new HashSet<>();

        //å®ç°map()å‡½æ•°
        public void map(Object key, Text value, Context context) 
        throws IOException, InterruptedException {  
            //å°†å­—ç¬¦ä¸²æ‹†è§£æˆå•è¯
            loadStopWords(context);
            String line = value.toString();
            String[] parts = parseCSVLine(line);

            String sentence = preprocessText(parts[0]);

            if(parts.length >= 2){
                StringTokenizer itr = new StringTokenizer(sentence);

                while (itr.hasNext()) {  
                    String token = itr.nextToken();
                    token = token.trim();
                    if(stopWords.contains(token) || token.isEmpty() || token.length() < 2) continue;
                    String OutputKey = parts[1] + "_" + token;     
                    word.set(OutputKey);
                    //å°†åˆ†è§£åçš„ä¸€ä¸ªå•è¯å†™å…¥word
                    context.write(word, one);
                }
            }


        }


        private String[] parseCSVLine(String line) {
            List<String> result = new ArrayList<>();
            boolean inQuotes = false;
            StringBuilder field = new StringBuilder();
            
            for (int i = 0; i < line.length(); i++) {
                char c = line.charAt(i);
                
                if (c == '"') {
                    inQuotes = !inQuotes;
                } else if (c == ',' && !inQuotes) {
                    result.add(field.toString());
                    field.setLength(0);
                } else {
                    field.append(c);
                }
            }
            result.add(field.toString());
            
            return result.toArray(new String[0]);
        }

        private String preprocessText(String text) {
            if (text == null || text.isEmpty()) {
                return "";
            }
            
            text = text.replaceAll("^\"|\"$", "");
            text = text.toLowerCase();
            text = text.replaceAll("[^a-zA-Z'\\s]", " ");
            text = text.replaceAll("\\d+", " ");
            text = text.replaceAll("\\s+", " ").trim();
            
            return text;
        }

        private void loadStopWords(Context context) throws IOException {
            URI[] cacheFiles = context.getCacheFiles();
            if (cacheFiles != null && cacheFiles.length > 0) {

                Path stopWordsPath = new Path(cacheFiles[0].toString());
                FileSystem fs = FileSystem.get(context.getConfiguration());
            
                try (BufferedReader reader = new BufferedReader(
                    new InputStreamReader(fs.open(stopWordsPath)))) {
                    String stopWord;
                    while ((stopWord = reader.readLine()) != null) {
                        stopWord = stopWord.trim().toLowerCase();
                        if (!stopWord.isEmpty()) {
                            stopWords.add(stopWord);
                        }
                    }
                }
            } else {
                System.err.println("No stop words file found in cache");
            }
        }
    }

    public static class IntSumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
        private IntWritable result = new IntWritable();
        //å®ç°reduce()å‡½æ•°
        public void reduce(Text key, Iterable<IntWritable> values, Context context )
            throws IOException, InterruptedException {
            int sum = 0;
            //éå†è¿­ä»£å™¨valuesï¼Œå¾—åˆ°åŒä¸€keyçš„æ‰€æœ‰value
            for (IntWritable val : values) {  
                sum += val.get();      
            }
            result.set(sum);
            //äº§ç”Ÿè¾“å‡ºå¯¹<key, value>
            context.write(key, result);
        }
    }

    public static class TopWordsReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
        private MultipleOutputs<Text, IntWritable> multipleOutputs;
        private TreeMap<Integer, List<String>> positiveWords = new TreeMap<>(Collections.reverseOrder());
        private TreeMap<Integer, List<String>> negativeWords = new TreeMap<>(Collections.reverseOrder());
        
        @Override
        protected void setup(Context context) throws IOException, InterruptedException {
            System.out.println("ğŸ¯ TopWordsReducer.setup() è¢« Hadoop è‡ªåŠ¨è°ƒç”¨");
            try {
                multipleOutputs = new MultipleOutputs<>(context);
                System.out.println("âœ… MultipleOutputs åˆå§‹åŒ–æˆåŠŸ");
            } catch (Exception e) {
                System.err.println("âŒ MultipleOutputs åˆå§‹åŒ–å¤±è´¥: " + e.getMessage());
                throw e;
            }
        }
        
        @Override
        public void reduce(Text key, Iterable<IntWritable> values, Context context) 
                throws IOException, InterruptedException {
            
            System.out.println("ğŸ¯ TopWordsReducer.reduce() è¢«è°ƒç”¨ï¼Œkey: " + key);
            String keyStr = key.toString();
            int totalCount = 0;
            
            // è®¡ç®—è¯¥å•è¯çš„æ€»å‡ºç°æ¬¡æ•°
            for (IntWritable val : values) {
                totalCount += val.get();
            }
            
            // è§£ææƒ…æ„Ÿå’Œå•è¯
            int underscoreIndex = keyStr.indexOf('_');
            if (underscoreIndex != -1) {
                String sentiment = keyStr.substring(0, underscoreIndex);
                String word = keyStr.substring(underscoreIndex + 1);
                
                // æ ¹æ®æƒ…æ„Ÿåˆ†ç±»å­˜å‚¨
                if (sentiment.equals("1")) {
                    positiveWords.computeIfAbsent(totalCount, k -> new ArrayList<>()).add(word);
                } else if (sentiment.equals("-1")) {
                    negativeWords.computeIfAbsent(totalCount, k -> new ArrayList<>()).add(word);
                }
            }
        }
        
        @Override
        protected void cleanup(Context context) throws IOException, InterruptedException {
            try {
                // è¾“å‡ºæ­£é¢æƒ…æ„ŸTop 100åˆ°å•ç‹¬æ–‡ä»¶
                outputTopWordsToFile("positive", positiveWords, 100);
                
                // è¾“å‡ºè´Ÿé¢æƒ…æ„ŸTop 100åˆ°å•ç‹¬æ–‡ä»¶
                outputTopWordsToFile("negative", negativeWords, 100);
            } finally {
                // ç¡®ä¿MultipleOutputsè¢«å…³é—­
                multipleOutputs.close();
            }
        }
        
        /**
         * è¾“å‡ºæŒ‡å®šæƒ…æ„Ÿçš„å‰Nä¸ªé«˜é¢‘è¯åˆ°æŒ‡å®šæ–‡ä»¶
         */
        private void outputTopWordsToFile(String outputName, 
                                        TreeMap<Integer, List<String>> wordMap, 
                                        int topN) 
                throws IOException, InterruptedException {
            
            int count = 0;
            for (Map.Entry<Integer, List<String>> entry : wordMap.entrySet()) {
                int frequency = entry.getKey();
                List<String> words = entry.getValue();
                
                // å¯¹åŒé¢‘ç‡çš„å•è¯æŒ‰å­—æ¯é¡ºåºæ’åº
                Collections.sort(words);
                
                for (String word : words) {
                    if (count < topN) {
                        // ä½¿ç”¨MultipleOutputsè¾“å‡ºåˆ°æŒ‡å®šåç§°çš„æ–‡ä»¶
                        multipleOutputs.write(outputName, new Text(word), new IntWritable(frequency));
                        count++;
                    } else {
                        break;
                    }
                }
                if (count >= topN) break;
            }
        }
    }
        

    public static void main(String[] args) throws Exception{ 
        //ä¸ºä»»åŠ¡è®¾å®šé…ç½®æ–‡ä»¶
        Configuration conf = new Configuration();
        //å‘½ä»¤è¡Œå‚æ•°
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        if (otherArgs.length != 3){ 
        System.err.println("Usage: wordcount <in> <out> <stop words>");
        System.exit(2);
        } 

        // è·å–è¾“å‡ºè·¯å¾„
        Path outputPath = new Path(otherArgs[1]);
        FileSystem fs = FileSystem.get(conf);
   
        // æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™åˆ é™¤
        if (fs.exists(outputPath)) {
            System.out.println("Output directory already exists, deleting it...");
            fs.delete(outputPath, true); // true è¡¨ç¤ºé€’å½’åˆ é™¤
        }

        Job job = Job.getInstance(conf, "word count");
        job.setJarByClass(Main.class); 

        job.setMapperClass(mapper.class);                 
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(TopWordsReducer.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        job.addCacheFile(new Path(otherArgs[2]).toUri());

        //è®¾ç½®è¾“å…¥æ–‡ä»¶çš„è·¯å¾„
        FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
        FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));

        // è®¾ç½®Reduceä»»åŠ¡æ•°é‡
        job.setNumReduceTasks(1);

        // æ·»åŠ å‘½åè¾“å‡ºå®šä¹‰
        MultipleOutputs.addNamedOutput(job, "positive", 
            TextOutputFormat.class, Text.class, IntWritable.class);
        MultipleOutputs.addNamedOutput(job, "negative", 
            TextOutputFormat.class, Text.class, IntWritable.class);

        System.out.println("Starting stock news analysis job...");
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}